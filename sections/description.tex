\section{Project Description \pagebudget{.5}}

% \comment{Meta comment: I think a lot of the technical content here can come from my thesis proposal. It has all of the technical projects other than the benchmarking project (which BCP should be able to write about — or maybe ask for Jessica’s help?) and it also has the background and related work. It may be useful to go to the individual papers for some deeper details, but I’d be surprised.}

In 2022, software is not just ubiquitous: it is pervasive.  As software
permeates our lives, so do the bugs the software contains, threatening our
time, our money, our privacy, and our health.
Luckily, techniques for ensuring the correctness of software have grown
alongside the software industry. A modern programmer has a wealth of tools
available to help them avoid potentially catastrophic errors.

One such tool,
property-based testing (PBT) combines formal software specification with random
testing to achieve low-effort, high-impact bug-finding. It has
seen enormous success, finding critical bugs in telecommunications
software~\cite{arts2006testing}, replicated
file-stores~\cite{hughes2014mysteries}, cars~\cite{arts2015testing}, and a range
of other programs~\cite{hughes2016experiences}. Select companies make PBT part of
their testing workflow and find it to be an invaluable tool for ensuring
correctness~\cite{Bornholt2021}.

But the PBT community must not rest on its laurels: there is still work to be
done. The literature has identified a number of challenges that make PBT
difficult or time consuming to apply in certain testing situations. One critical
class of challenges concerns the random data generators that testers use as part
of the PBT process.
Successful PBT relies on random data that is both well distributed and ``valid''
for the system under test. I have spent the last few years exploring ways to
make effective random generators more powerful and easier to write, and I will
continue that work in my dissertation.

Additionally, it is clear that there are also ``unknown unknowns'': challenges
facing PBT, particularly those important to software developers, that the
research community is not yet aware of. I have begun a series of need-finding
studies, consisting of semi-structured interviews with developers, to uncover
and hopefully solve some of these hidden challenges. This work will form the
second major theme of my dissertation.

\todo{
[MODEL AFTER THESIS INTRO / CONCLUSION]
\begin{itemize}
   \item High level: Advance the theory and practice of PBT, making it more valuable to a wider range of software engineers
   \item PBT is great
\begin{itemize}
      \item For people who like formal methods, it’s a way to write a formal spec and check it without doing full verification
      \item Even for people who don’t, it’s been extremely effective finding bugs in practice
         \item Cite…
      \item (?) And people really like it (maybe pull quotes from preliminary study)
\end{itemize}
   \item But there is still room for PBT to grow (maybe stats, feel free to refine this argument more)
   \item We want to advance the theory and practice of PBT so it is more valuable to SEs
\end{itemize}
}

\subsection{Background and Related Work \pagebudget{1.5}}

\subsubsectionstar{Property-Based Testing}%
%
Property-based testing (PBT) is a form of random testing~\cite{hamlet1994random}
that was popularized by the QuickCheck~\cite{DBLP:conf/icfp/ClaessenH00} library
in Haskell. In PBT, users write executable functions that act as partial
specifications of a function under test. For example, a tester might write the
following property to specify the \lstinline{insert} function for an
implementation of a binary search tree (BST):
\begin{lstlisting}
  prop_insertCorrect x t = isBST t ==> isBST (insert x t)
\end{lstlisting}
This property is an ordinary function that takes an integer and a tree as input
and asserts that if the original tree satisfies the BST invariant, then so does
the tree after inserting the integer. There are a myriad of different kinds of
properties that one might use to specify a system; a good source of examples is
\citet{HowToSpecifyIt}.

With a property in hand, a tester then passes a series of inputs to the property
and checks that the property evaluates to \lstinline{True} for each input.  If
some input causes the property to fail, then it constitutes a {\em
counterexample} to the property and potentially a bug in the program. If no
counterexample is found after the tester's time budget has elapsed, the tester
will have gained confidence that the property holds in general.

In this dissertation I focus on the case of random PBT, where the series of
inputs that check the property are generated by some random process, but there
are alternatives. In particular, {\em enumerative testing} advocates
deterministically listing every possible input from the smallest to the largest,
relying on the ``small scope hypothesis''~\cite{jackson1996elements} that most
bugs can be found with ``small'' inputs. There are a variety of systems that use
this technique~\cite{DBLP:conf/haskell/RuncimanNL08,leancheck}. Forms of model
checking can also be considered alternatives to random PBT; their approaches
vary but at their core model checkers are often tools for searching an input
space for counterexamples~\cite{biere2009bounded}.

Despite the success of the enumerative testing and model checking, random
generation is still a dominant player in the PBT space. Its success is often
attributed to the fractal nature of ``big'' test cases---many structures are
self-similar, so testing with one big structure also tests the code with the
exponentially many smaller sub-structures. This effect is powerful, but it still
takes a bit of work to get random generation ``right.'' Many have pointed out
that the distribution that inputs from drawn from is incredibly important for
effective testing, so programmers are often forced to choose a distribution
manually~\cite{DBLP:conf/icfp/ClaessenH00}. Even more importantly, testers need
to ensure that the sampled inputs are {\em valid} to test with; I discuss this
problem in the next section.

\subsubsectionstar{The Valid Generation Problem}%
%
Note that the property above has a {\em precondition} (which I also refer to
equivalently as a {\em validity condition} or {\em input constraint}): the
property is vacuous if the input tree is not a valid BST. This can be problematic,
because many preconditions are difficult to satisfy randomly; in the case above
we would need to randomly stumble on valid BSTs, which is very unlikely for
trees that are more than a few nodes deep. I call this the {\em valid generation
problem}. In the next section I will discuss the standard solution to this
problem in PBT---hand-written {\em monadic generators}---but first here is a
short overview of other options.

The solutions to the valid generation problem fall on a spectrum from fully
automatic to fully manual. The most automatic possible approach is to simply
generate inputs as normal, ignoring preconditions entirely, and throw away any
that do not satisfy the precondition. As I mentioned above, this is extremely
inefficient when the precondition is {\em sparse}, or unlikely to be satisfied
randomly.

Equally automatic, but often more effective, are coverage-guided approaches like
those used by {\em fuzzers}. Fuzzers like AFL~\cite{afl-readme} measure the code
coverage achieved by each input they try. If an input does not achieve coverage
of new program branches, it is discarded, but if the input is deemed
``interesting,'' then it may be mutated and tried again in an attempt to explore
even more new code paths. This process makes finding valid inputs more likely
because optimizing for code coverage encourages exploration of paths deeper in
the program (i.e., past the point where the precondition is checked).
Unfortunately, this only works so well, and again begins to fail with very
sparse preconditions.

A different approach that is {\em almost} entirely automatic is {\sc
Target}~\cite{loscher2017targetedpbt}; it uses search strategies like hill
climbing and simulated annealing to guide generation to more useful inputs.
\citeauthor{loscher2017targetedpbt}'s approach works well when the notion of
validity is in some way continuous (i.e., an input is not simply invalid, it is
$X\%$ valid), but this is often not the case.

Some approaches use machine learning to automatically generate valid inputs.
{\sc Learn\&Fuzz}~\cite{godefroid2017learn} generates valid data using a
recurrent neural network.  This solution seems to work best when a large corpus
of inputs is already available and the validity condition is more structural
than semantic. In the same vein, {\sc RLCheck}~\cite{DBLP:conf/icse/ReddyLPS20}
uses reinforcement learning to guide a generator to valid inputs.

For preconditions that are primarily structural, {\em grammar-based fuzzing}
provides a compelling (if slightly more manual) solution. In {\em
Grammar-based whitebox fuzzing}~\cite{godefroid2008grammar} a context-free
grammar (CFG) is used to constrain the fuzzer's output. Over the years, many
versions of this paradigm have been developed, including ones that use
pre-written fragments of the input language to give the mutator interesting
things to work with~\cite{holler2012fuzzing} and ones that use genetic
programming to find more interesting inputs~\cite{veggalam2016ifuzzer}. The
newest grammar-based fuzzing approaches use the grammar to do more structured
mutation of values~\cite{wang2019superion,srivastava2021gramatron}. These ideas have also been integrated
into PBT in the FuzzChick library~\cite{DBLP:journals/pacmpl/Lampropoulos0P19}.

Moving into the range of ``mostly manual'' solutions, there are a variety of
solver-aided languages for expressing generators for data with preconditions.
\citeauthor{dewey2017automated} proposed using constraint logic programming
(CLP) to define generators for interesting structures like Rust
programs~\cite{dewey2017automated}.  The {\sc Luck} language~\cite{LuckPOPL}
also uses a solver, but a bespoke one, to define generators and validity
predicates at the same time. \citet{steinhofel2022input} use a
grammar and SMT-expressible constraints on a structure to generate
precondition-satisfying values.

Finally, {\em Generating Good Generators}~\cite{lampropoulos2017generating} an
outlier on the spectrum: technically it is a manual approach since it requires
users to first express their validity predicates as inductive relations in Coq,
but in Coq it is likely that the user already has an inductive relation
available! {\em Generating Good Generators} is a great approach in the
situations where it applies.

\subsubsectionstar{Monadic Generators}%
%
The most manual, but arguably the most flexible, solution to the valid
generation problem is write {\em monadic} generators.

We represent generators using {\em monads\/}~\cite{moggi1991notions}. A monad is
a type constructor (e.g., \lstinline{List}, \lstinline{Maybe}, etc.)
\lstinline{M} equipped with two operations,
\begin{lstlisting}
  return :: a -> M a
\end{lstlisting}
\noindent and
\begin{lstlisting}
  (>>=) :: M a -> (a -> M b) -> M b
\end{lstlisting}
\noindent (pronounced ``bind''). Conceptually, \lstinline{return} is the
simplest way to put some value into the monad, while bind gives a way to
sequence operations that produce monadic values.

We can use these operations to define {\sf genTree} like we would in QuickCheck:
\begin{lstlisting}
  genTree :: Int -> Gen Tree
  genTree 0 = return Leaf
  genTree $h$ = do
    c <- frequency [(1,False), (3,True)]
    case c of
      False -> return Leaf
      True -> do
        x <- genInt
        l <- genTree ($h$ - 1)
        r <- genTree ($h$ - 1)
        return (Node l x r)
\end{lstlisting}
We use the monadic operations (along with \lstinline{frequency}) to generate a
random tree of integers. The expression \lstinline{return Leaf} is a degenerate
generator that always produces the value \lstinline{Leaf}---this is what we mean
by the ``simplest way to put a value into the \lstinline{Gen} monad.''

Rather than use \lstinline{(>>=)} explicitly, we use \lstinline{do}-notation,
where
\begin{lstlisting}
  do
    a <- x
    f a
\end{lstlisting}
\noindent is syntactic sugar for \lstinline{x >>= f}. In the context of the
\lstinline{Gen} type, this operation samples from a generator \lstinline{x} to
get a value \lstinline{a} and then passes it to \lstinline{f} for further
processing---this is what we mean by ``sequencing operations.''

\smallskip

Monadic parsers are maximally expressive.  They can generate values satisfying
arbitrary computable constraints (e.g., it is possible to write a monadic
generator for well-typed System F terms), subsuming less powerful
representations like probabilistic context-free grammars.

For example, the following monadic generator generates (only) valid binary
search trees:
\begin{lstlisting}
  genBST :: (Int, Int) -> Gen Tree
  genBST (lo, hi) | lo > hi = return Leaf
  genBST (lo, hi) = do
    c <- frequency [(1,False), (3,True)]
    case c of
      False -> return Leaf
      True -> do
        x <- genRange (lo, hi)
        l <- genBST (lo, x - 1)
        r <- genBST (x + 1, hi)
        return (Node l x r)
\end{lstlisting}
\noindent The generator maintains the BST invariant by keeping track of the
minimum and maximum values available for a given sub-tree and ensuring that all
values to the left of a value are less and that all values to the right of a
value are greater.  This kind of generator is impossible to express as a
stochastic CFG, since there is dependence between the choice of value
\lstinline{x} and the choices of sub-trees. Our examples are mostly focused on
simple (non-dependent) generators to streamline the exposition, but our theory
applies to the full class of monadic generators with finitely supported
distributions.

\subsubsectionstar{Why Us?}%
%
\todo{A short paragraph about what a great team we are, how the PI
  qualifications complement each other, and what kind of students we aim to
  support.  Include a pointer to the work plan section below.}

\subsection{Extending the Foundation \pagebudget{3}}

\todo{
\begin{itemize}
   \item Story
\begin{itemize}
      \item The research community has identified that random generation (and in particular, the valid generation problem)[b] causes problems for testers
      \item This shows up in prior work, and also in realistic examples (e.g., the fuzzing community really cares about this!)
      \item We’ve already done some work to explore new abstractions for random generation (free generators) and we have more that we want to try (reflective generators)
      \item In addition, the PBT community is missing tools to empirically evaluate generation strategies
      \item And the PBT literature is also woefully disconnected from the fuzzing literature, where they have their own partial solutions to this problem
\end{itemize}
   \item Prior Work - Free generators [CHAPTER 1[c] OF THESIS PROPOSAL is a
   source, but it's way too long -- we need to write a compact precis of the
   crucial points]
   (perhaps also some other prior things)
   \item Planned Work - Reflective generators [CHAPTER 2 OF THESIS PROPOSAL]   (needs new work on evaluation; maybe rests on benchmarking infrastructure; validity-preserving mutation scheme needs to be evaluated by real implementation and measurement)
   \item Planned Work - Empirical Evaluation Playground [JESSICA OR BENJAMIN WRITE] (can ultimately be used for Benchmarking; in the short term, it’s a playground for individual PBT efforts to see how they are doing)
   \item Speculative Work - Add PBT incrementally to a fuzzing system [CHAPTER 3 OF THESIS PROPOSAL](follows directly from the free and reflective generators work)
\end{itemize}
}

\subsection{Finding out what working programmers need \pagebudget{3}}

\todo{
\begin{itemize}
   \item Story
\begin{itemize}
      \item The projects above follow the lead of prior work, solving problems that have already been identified, but we have no reason to believe that those problems are exhaustive
      \item Indeed, there may be high-leverage opportunities to improve PBT that have nothing to do with the valid generation problem
      \item We’re in the process of uncovering “unknown unknowns” by talking to PBT users about their experiences - we’ve already done a preliminary study, and we plan on talking to Jane Street developers for a full-scale study
      \item We’re not sure what we should do after that, but the preliminary study gave us some ideas
\begin{itemize}
         \item We can obviously keep talking to users (via surveys or observations)
         \item We also identified that there are likely workflow improvements that could help PBT fit into a developer’s environment better (and user-centered design opportunities there)
         \item We may even find interesting PBT opportunities at Jane Street that will give us a hands-on opportunity to solve problems that real developers are actively dealing with
\end{itemize}
\end{itemize}
   \item Prior Work - Pilot study [CHAPTER 4 OF THESIS PROPOSAL / HATRA]
   \item Planned Work - Jane Street Study [CHAPTER 4 OF THESIS PROPOSAL / HATRA]
\end{itemize}
}


Part 1 of the ``unknown unknowns''.
Jane Street study, preliminary study, observations, surveys.

In this aim, we plan to set course for research in PBT, both broadly and for the
future directions of our group. We will conduct a series of formative studies,
each addressing one of three main goals:

\subsubsectionstar{Understanding Challenges to Using PBT Tools}

The first step is to conduct qualitative interviews to understand the challenges
that programmers face when using PBT tools.

Here I will elaborate on the design of the Jane Street study.

We plan to partner with Jane Street,
LLC to gain deeper insights into the challenges facing PBT in industrial
settings and to begin to explore potential solutions.

\paragraph{Research Questions}
The research questions for the full-scale study will again address our central
question:
How can the research community make PBT more valuable
for software developers?

Our preliminary study highlighted five sorts of challenges that PBT
faces: what might be called {\em property}, {\em generator}, {\em workflow},
{\em learning}, and {\em social} challenges. We expect that
learning challenges are best explored in a classroom setting (see
Section~\ref{sec:future}), and that social challenges are too intertwined with
challenges of other sorts to study directly. Accordingly, our research
questions for the full-scale study will focus on property, generator, and workflow
challenges.
\begin{itemize}
\item[\bf RQ1.] What support do developers need to help them imagine properties?
\item[\bf RQ2.] What kinds of generators do testers need to exercise their
  properties effectively? Do they have specific precondition and/or distributional
  requirements?
\item[\bf RQ3.] What aspects of the developer workflow around PBT need improvement?
\item[\bf RQ4.] What concrete changes could be made to modern PBT systems
  to improve effectiveness and usability?
\end{itemize}
{\bf RQ1}, {\bf RQ2}, and {\bf RQ3} relate to property,
generator, and workflow challenges, respectively.
{\bf RQ4} more directly asks how existing systems might
be improved. This final question will help to keep us focused,
reminding us that participants likely have the context and knowledge not
only to identify challenges but also to suggest
solutions!

\paragraph{Study Population}
As in the preliminary study, our primary tool will be interviews with
developers. We will tentatively partner with Jane Street, LLC, a large
financial technology firm,
interviewing around 30 Jane Street employees about their experiences using PBT.

Jane Street has a number of qualities that makes it an ideal place for
this study. To start, Jane Street developers use
a variety of testing tools, including PBT. This gives us a place to start
when asking questions, since participants will likely have seen PBT before,
and it means that will be score for exploring trade-offs between PBT and
other forms of testing.
Additionally, Jane Street developers famously build almost all of their
systems in OCaml, a mostly functional programming language with strong support
for static typing and modularity. This unified ecosystem
will allow
us to control for a number of potentially confounding factors: all of the
developers we talk to will have access to the same PBT tools and the same
libraries, language-level programming abstractions, house coding rules,
etc. (which might make testing easier or harder).

Naturally, carrying out a study at a single firm has potential drawbacks as
well. The most obvious is that our results may not generalize: We
cannot guarantee that our findings will apply outside of the OCaml ecosystem (and
other ecosystems like it). However, Jane Street is home to a diverse array of
software systems, including trading systems, quantitative
algorithms, networked systems, and hardware description code~\cite{signalsandthreads}.
We hope that the breadth of these programming tasks will mean that the software
developers that we talk to will come to the discussion with a wide variety of
experiences.

\paragraph{Stakeholders}
Our initial discussions with Jane Street leadership made it clear that there are
two distinct populations at Jane Street that we can learn from. The group we had
initially planned to talk to was developers who have used PBT in
their work at the firm. These can tell us about how PBT helped them,
what challenges they faced, and what techniques they use instead of
PBT to check that their code is correct. But we we can also learn
a ton by talking to PBT {\em stakeholders} at Jane Street---i.e., the folks who
build and maintain the PBT systems themselves.  Since talking with
stakeholders may also help us to refine our developer interview script, we will
interview them first.

\paragraph{Interview Plan}
Each interview will be allotted a one hour slot, to account for a more detailed
interview script than the one in the preliminary study. As mentioned above, we
will start by interviewing stakeholders. Our prompts will primarily set the
stage for our developer interviews and establish background that will help us to
interpret our results, but stakeholders may also be able to help us answer {\bf
RQ4} (and to a lesser extent other research questions) directly. We will pick
the stakeholder's brains about opportunities to support users
of PBT, phrasing our prompts to encourage creative thinking.

After talking to stakeholders, we will begin the developer interviews. The
script for these interviews will depend on our conversations with stakeholders,
but at a high level we will aim to answer our research questions as directly as
possible. Much like the preliminary study, we will have our participants tell us about a
specific experience with PBT and ask them about the properties and generators
that they used (hopefully giving us insights about {\bf RQ1} and {\bf RQ2}).  We
will also ask about whether or not they are using PBT on their {\em current}
project (and if not, why not). Finally, we will ask questions addressing
{\bf RQ3} and {\bf RQ4} directly.

\paragraph{Preliminary results}

\subsubsectionstar{Characterizing the Potential Reach for PBT Tools}

We will conduct a survey with the purpose of understanding the impact that
improved PBT tools could have in industry, if major usability issues were
addressed. We see this survey as crucial in understanding the amount of
resources that should be devoted to PBT research. Furthermore, this
questionnaire will help shed light into which of the usability challenges from
the interview study, if addressed, are most likely to impact a broad set of
current and prospective users of PBT tools.

\subsubsectionstar{Understanding the Structure of PBT Tasks in Detail}

The next step is to more deeply characterize the obstacles faced with specific
tools and tasks through close observation. We anticipate conducting observations
of participants formulating properties and creating generators, as we expect
that close observation of developers performing these tasks will yield yet
additional detail about ways that developers are supported and not supported by
the tools they use today to a level of depth we will not achieve with the
interviews.

\subsection{Exploiting the Foundations to Build Powerful, Interactive PBT Tools \pagebudget{3}}

Upon the advanced technical foundation from Aim 1 and the refined understanding
of programmers' needs from Aim 2, our final aim (Aim 3) will focus on the
development of programmer-facing tools that allow them to leverage properties in
testing their code more efficiently and effectively.

While the specific focus of our tool design and research efforts will be
continually refined on the basis of what we learn from Aim 2, below we detail
several directions that we expect to lead to the design of tools that are both
innovative within the research community, as well as potentially impactful,
drawing on the lessons learned from the preliminary need-finding research we
have done to date as well as our own intuitions, and as critical users and
engaged members of the communities for these tools.

\todo{Discuss:

\begin{itemize}

% \item Some of the tools we propose in this section may depend on a technical
% background we do not have on this team. For instance, property generation.
% Should we be keeping the scope of the proposed work to those where we as a team
% have expertise in the backend technologies? After discussing with BCP, we need
% not limit ourselves to areas where we are at present the leading experts. Let's
% draft the descriptions, see the ones we are excited about, wave away some
% of the details that we have not yet educated ourselves, and go from there.

\item We should ask Jane Street for a letter of support indicating their
willingness to collaborate on the need-finding activities.  (Yes!  And we
should write it for them... :-)

\end{itemize}
}

\subsubsectionstar{Interactive property specification}

Developers in the preliminary interview study indicated that while they knew their software would benefit from property-based testing, sometimes they had difficulty imagining which properties to test. One area that could benefit from innovation in PBT tools is in designing tools that help programmers imagine properties in situations like these.

To date, research has shown the potential for automated tools to extract invariants describing a program's behavior\cite{ammons2002mining,le2018deep,claessen2010quickspec}. However, the integration of such tools into developer workflows is non-trivial. We posit that a usable tool that can help with imagining properties would need the following features:

\textit{Readable code generation}. While prior techniques have succeeded in generating invariants, we expect that users of PBT systems would benefit from having properties generated in the language of their property-based testing tools. Furthermore, there are some variants about systems that may be so complex that they require significant comprehension time for users (i.e., those involving a large number of clauses). In such cases, a tool may way to generate simpler variants of properties first, and allow developers to refine them on their own.

\textit{Generating important properties}. Non-trivial programs can be described by an overwhelmingly large number of properties, many of which describe only incidental aspects of the program's behavior that do not need to be tested. How can tools produce those properties that developers would want to have tested? We believe that this is a problem that can be best solved with a mixed-initiative approach~\cite{allen1999mixed}---that is, judiciously incorporating both developer input and automation. Developer could guide a specification mining tool to extracting relevant properties through input mechanisms such as (1) identifying regions of code that are likely to lead to an adverse behavior such as an exception or a logical error; (2) providing unit test cases that test a special case of a generalized property; and (3) indicating aspects of interest on input and output data during exploration in a debugging REPL.

\textit{Property refinement}. Tools could help a developer refine generated properties. If a generated property is too relaxed, the tool could request that developer provides a counterexample that should trigger a failure, and then regenerate the property. If a generated property is too strict, a tool could allow a programmer to mark a counterexample that was generated by the PBT tool as spurious, i.e., not indicating an actual failure of the program. In each of these cases, the property generator may have generate multiple properties for a developer to review, each of which may satisfy the refinements that a developer has provided.

\textit{Plan of work}: Incorporating known, widely-used specification mining tools such as QuickSpec~\cite{claessen2010quickspec}\ldots{}

% One challenge identified by software developers we have spoken with is that it can be difficult to come up with a property to test with property-based testing tools. Perhaps tools could help programmers come up with, and express, properties that they wish to be tested. To design such tools, we will adapt techniques from the specification mining literature to generate candidate properties (e.g.,~) and interfaces that help programmers select from, and refine, generated properties.
% 
% A first step will be to generate candidate properties. These will be generated using specification mining techniques. Specifications will need to be mapped from an abstract representation of the property to an expression of that property in the programming language, such as Hypothesis' property specification language. A major challenge is that a specification mining technique will produce many spurious properties which do not describe aspects of the program that the programmer wishes to test. Affordances will be added to the programming environment to allow a program to select subsets of code that manipulate properties of interest; and to generalize from behaviors that are implied by individual unit tests, or observations made during debugging, to greatly limit the space of generated properties.
% 
% A second step will be to assist in the refinement of properties. In some cases, generated properties will be too broad; for instance, . if the testing tools yield a counterexample, the counterexample may be an indicator that a property is insufficiently strict, rather than an indication that the program is incorrect. @Andrew, continue from here\ldots{}
% 
% Motivation: Informants struggled to figure out what to test. informants had an intuitive idea of what “right” and “wrong” was. Perhaps they could have been helped with a tool that refined that expectation into something that was formal.
% 
% Plan of work: A first step in this process might be a tool that refines a wrong specification that has some counterexamples into a clean, correct specification. When a counterexample is encountered, you can fix the program if it represents a bug, or you will have to refine a property if the property was not written correctly.
% Alternatively, a greenfield specification maker might depend on a machine learning backend. We need to know more about how this works. Perhaps speak to Mayur about unit test generation. The tool design would focus on coming up with usable property specifications, and potential some user input (e.g., pointing to parts of programs that should be involved in property creation). Could specifications be provided as natural language? QuickSpec works okay for Haskell using static analysis to determine invariants. We would need someone with ML or program synthesis background to work on this project.
% 
% Example: For a serialization / deserialization pair of functions, testing that the serialized deserialized string is the same version as the original string; the refinement is to exclude Unicode strings, which do not have to be supported by serialization functions.

\subsubsectionstar{Visualizing and tuning data distributions}

% (this topic is what Joe is most excited about)

% For visualizing data distributions...

Plan of work: easily computable summary statistics; as well as user-defined metrics for understanding what you care the most about from the distribution. Seeing what the “average” data structure is that is getting generated. For multimodal data, what are the different modes of data. The set of data types to be handled in PBT are: algebraic data types, lists, trees (this would also cover programs). Joe thinks we already have good visualizations for numbers, booleans, and strings; it is compositional data types that we lack good visualizations for. People need to (1) see representative examples (2) understand spread (3) indicate areas of the space that should not be explored.

% For tuning data distributions...

Plan of work: indicating areas of the distribution that should not be generated.

Example: writing a generator of programs (for instance, to test out a compiler). You want lots of different programs that make sense in different ways. You want large ones, small ones, ones that use variables in coherent ways, ones that don’t overuse certain constructs, ones that use a variety of different language features. You want the generated programs to be representative of those that people might write. You also want some weird programs to catch the edge cases, but you don’t want all weird programs. (How big, how deep, how wide of programs?). Also, for trees, one might want to specify heights and breadths of the tree.

\subsubsectionstar{Debugging support for understanding counterexamples}

Once a PBT tool generates a counterexample of where a property fails, a programmer will need to understand what in an input caused the program to fail. This task can be rather challenging because generated inputs can be complex, deep data structures \todo{Do we have a reference that implies the complexity of generated counterexamples?}. Methods for making it clearer why a counterexample fails could be to generate additional inputs that are very close to the counterexample that are actually correct, to run the program up to the point where the traces of the programs begin to diverge, and then to drop a programmer into a debugging environment where they can query the state of the program and step through the remainder of the execution. PI Head has prior work designing debugging tools that help programmers understand trace divergences in an educational setting~\cite{suzuki2017tracediff}.

\subsubsectionstar{Reconciling generator API design with imperative language idioms}

Motivation: How do you design a generator DSL in an imperative language? A generator uses higher-level functions in a way that might be confusing to people who used Python.  (e.g., passing a generator of numbers to a generator of lists to get randomized lists of numbers). Is there a way of designing APIs for generators that can make the composition of these types of generators easier to reason about and express for some programmers?

(Joe says the DSLs are well-designed, but the code is hard to debug. How do you write a generator that works really well, that has a good data distribution and finds bugs? See below.)

Plan of work. Not sure. This might require some discussions with more uses of Hypothesis-like libraries.

Next steps—get examples of sloppily-expressed PBtests in Python and then think through how they would be written more clearly.

\subsubsectionstar{Integration with continuous integration workflows}

\todo{Section 6.2 of Harry's thesis proposal.}

\subsubsectionstar{Tailoring PBT for financial systems}

I am not sure what should go here. I am a bit wary of focusing specifically on developing tools for financial systems if the focus of this grant proposal is to make PBT tools more broadly useful.

\subsection{Education \pagebudget{1}}

\subsection{Plan of Work \pagebudget{.5}}

\todo{(with a pretty pert chart or suchlike...)}

\subsection{Broader Impacts \pagebudget{.5}}
The Project Description must contain, as a separate section within the narrative, a section labeled ``Broader
Impacts of the Proposed Work". This section should provide a discussion of the broader impacts of the proposed
activities. Broader impacts may be accomplished through the research itself, through the activities that are
directly related to specific research projects, or through activities that are supported by, but are complementary to
the project. NSF values the advancement of scientific knowledge and activities that contribute to the
achievement of societally relevant outcomes. Such outcomes include, but are not limited to: full
participation of women, persons with disabilities, and underrepresented minorities in science, technology, engineering, and
mathematics (STEM); improved STEM education and educator development at any level; increased public
scientific literacy and public engagement with science and technology; improved well-being of individuals in
society; development of a diverse,globally competitive STEM workforce; increased partnerships between
academia, industry, and others; improved national security; increased economic competitiveness of the United
States; and enhanced infrastructure for research and education.

\subsection{Results from Prior NSF Support \pagebudget{.5}}
If any PI or co-PI identified on the project has received NSF funding (including any current
funding) in the past five years, in formation on the award(s) is required,
irrespective of whether the support was directly related to the proposal or not.
In cases where the PI or co-PI has received more than one award (excluding amendments),
they need only report on the one award most closely related to the proposal. Funding includes not just salary
support, but any funding awarded by NSF. The following information must be provided:\\

\noindent
\emph{\underline{Name of PI}}: NSF-Program (Award Number) ``Title of the Project'' (\$AMOUNT, PERIOD OF SUPPORT).
{\bf Publications:} List of publications resulting from the NSF award. A complete bibliographic citation for each
publication must be provided either in this section or in the References Cited section of the proposal); if
none, state: ``No publications were produced under this award.'' {\bf Research Products:} evidence of research products
and their availability, including, but not limited to: data, publications, samples, physical collections, software,
and models, as described in any Data Management Plan.

% \subsubsection{Proposed Study}
% The Project Description should provide a clear statement of the work to be undertaken and must include:
% objectives for the period of the proposed work and expected significance; relation to longer-term goals of the PI's
% project; and relation to the present state of knowledge in the field, to work in progress by the PI under other
% support and to work in progress elsewhere.
%
% The Project Description should outline the general plan of work, including the broad design of activities to be
% undertaken, and, where appropriate, provide a clear description of experimental methods and procedures.
% Proposers should address what they want to do, why they want to do it, how they plan to do it, how they will
% know if they succeed, and what benefits could accrue if the project is successful. The project activities may be
% based on previously established and/or innovative methods and approaches, but in either case must be well
% justified. These issues apply to both the technical aspects of the proposal and the way in which the project may
% make broader contributions.

\subsection{More stuff to not forget :-)}

Unfunded collaborations: Any substantial collaboration with individuals not included in the budget should be described in the Facilities, Equipment and Other Resources section of the proposal (see Chapter II.C.2.i) and documented in a letter of collaboration from each collaborator. Such letters should be provided in the supplementary documentation section of FastLane or Research.gov and follow the format instructions specified in Chapter II.C.2.j. Collaborative activities that are identified in the budget should follow the instructions in Chapter II.D.3.

Remember to not use any URLs in the project description!  (They are
encouraged in the references.)
