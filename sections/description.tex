\section{Project Description \pagebudget{.5}}

\todo{
  \begin{itemize}
    \item Testing is a huge part of the modern software development process
    \item There are many flavors of testing (unit testing, integration testing,
    etc.) that are popular and effective
    \item The things that SE has adopted are powerful, and there are tools that
    are even more powerful
    \item
One such tool,
property-based testing (PBT) combines formal software specification with random
testing to achieve low-effort, high-impact bug-finding. TODO Rich theoretical foundation. It has
seen enormous success, finding critical bugs in telecommunications
software~\cite{arts2006testing}, replicated
file-stores~\cite{hughes2014mysteries}, cars~\cite{arts2015testing}, and a range
of other programs~\cite{hughes2016experiences}. Select companies make PBT part of
their testing workflow and find it to be an invaluable tool for ensuring
correctness~\cite{Bornholt2021}.
    \item Increasing the impact of PBT in industry would improve productivity
    and make software more robust. What would that take?
    \item We're in the middle of an in-depth formative study to find out just
    that
    \begin{itemize}
      \item Still doing analysis, but some broad themes have become clear
      \item List high-level theme categories
    \end{itemize}
    \item The goal of the project is to capitalize on that data and advance PBT
    by:
    \begin{enumerate}
      \item Understanding the foundation: challenges PBT faces in industry
      \item Addressing difficulties in specification, generation, and testing
      validation with theoretically motivated and rigorously designed tools
      \item Setting up comprehensive resources for education
    \end{enumerate}
    \item In the following section, we describe the study in some detail and use
    it to motivate the work that we propose in this project
    \item MOTIVATION SECTION
    \begin{itemize}
      \item Motivating questions for JS study
      \item Lay out study parameters in some (but not much) detail
      \item Discuss some emerging themes
      \begin{itemize}
        \item Give justification in the form of quotes for some
        \item Say why the themes are important, how they line up with existing
        understanding
        \item Situate themes relative to their categories
      \end{itemize}
      \item Tie everything together
      \begin{itemize}
        \item The themes of this study map onto the projects that we plan to
        carry out
        \item Each theme category has a section below, each project in those
        sections directly serves one or more of the themes in that category
        \item Here's what we're going to do...
      \end{itemize}
    \end{itemize}
  \end{itemize}
}

\subsectionstar{Motivation: A Formative Study \pagebudget{2}}

\subsubsectionstar{Context: Property-Based Testing}%
%
Property-based testing (PBT) is a form of random testing~\cite{hamlet1994random}
that was popularized by the QuickCheck~\cite{DBLP:conf/icfp/ClaessenH00} library
in Haskell. In PBT, users write executable functions that act as partial
specifications of a function under test. For example, a tester might write the
following property to specify the \lstinline{insert} function for an
implementation of a binary search tree (BST):
\begin{lstlisting}
  prop_insertCorrect x t = isBST t ==> isBST (insert x t)
\end{lstlisting}
This property is an ordinary function that takes an integer and a tree as input
and asserts that if the original tree satisfies the BST invariant, then so does
the tree after inserting the integer. There are a myriad of different kinds of
properties that one might use to specify a system; a good source of examples is
\citet{HowToSpecifyIt}.

With a property in hand, a tester then passes a series of inputs to the property
and checks that the property evaluates to \lstinline{True} for each input.  If
some input causes the property to fail, then it constitutes a {\em
counterexample} to the property and potentially a bug in the program. If no
counterexample is found after the tester's time budget has elapsed, the tester
will have gained confidence that the property holds in general.

In this dissertation I focus on the case of random PBT, where the series of
inputs that check the property are generated by some random process, but there
are alternatives. In particular, {\em enumerative testing} advocates
deterministically listing every possible input from the smallest to the largest,
relying on the ``small scope hypothesis''~\cite{jackson1996elements} that most
bugs can be found with ``small'' inputs. There are a variety of systems that use
this technique~\cite{DBLP:conf/haskell/RuncimanNL08,leancheck}. Forms of model
checking can also be considered alternatives to random PBT; their approaches
vary but at their core model checkers are often tools for searching an input
space for counterexamples~\cite{biere2009bounded}.

Despite the success of the enumerative testing and model checking, random
generation is still a dominant player in the PBT space. Its success is often
attributed to the fractal nature of ``big'' test cases---many structures are
self-similar, so testing with one big structure also tests the code with the
exponentially many smaller sub-structures. This effect is powerful, but it still
takes a bit of work to get random generation ``right.'' Many have pointed out
that the distribution that inputs from drawn from is incredibly important for
effective testing, so programmers are often forced to choose a distribution
manually~\cite{DBLP:conf/icfp/ClaessenH00}. Even more importantly, testers need
to ensure that the sampled inputs are {\em valid} to test with; I discuss this
problem in the next section.

\bcp{Related work to mention: HypoFuzz \url{https://hypofuzz.com}}

\subsectionstar{Contributions}

%
\todo{Outline project}

\todo{A short paragraph about what a great team we are, how the PI
  qualifications complement each other, and what kind of students we aim to
  support.  Include a pointer to the work plan section below.}

\subsection{Foundation: Completing Formative Analysis \pagebudget{2}}
\subsubsection{Prior Work: Preliminary Study}

The first step is to conduct qualitative interviews to understand the challenges
that programmers face when using PBT tools. To this end, we plan to undertake an
interview study with our research partner, Jane Street, LLC\footnote{See letter
of support in the appendix.} to develop a deep understanding of the challenges
programmers face using PBT in industrial settings as well as being to explore
potential solutions.

\textbf{Research questions}.
Our key research question will be, \emph{How can the research community make PBT
more valuable for software developers?} More specifically, we seek
answers to the following questions:

\begin{itemize}[noitemsep,leftmargin=4em]
\item[\bf RQ1.] What support do developers need to help them imagine properties? \todo{Reword, the notion of ``imagining'' properties has not yet been introduced.}
\item[\bf RQ2.] What kinds of generators do testers need to exercise their
  properties effectively? Do they have specific precondition and/or distributional
  requirements?
\item[\bf RQ3.] What aspects of the developer workflow around PBT need improvement?
\item[\bf RQ4.] What concrete changes could be made to modern PBT systems
  to improve effectiveness and usability?
\end{itemize}

{\bf RQ1}, {\bf RQ2}, and {\bf RQ3} relate to property,
generator, and workflow challenges, respectively.
{\bf RQ4} more directly asks how existing systems might
be improved. This final question will help to keep us focused,
reminding us that participants likely have the context and knowledge not
only to identify challenges but also to suggest
solutions.

\textbf{Research site}. We will partner with Jane Street, LLC, a large
financial technology firm.
Jane Street has a number of qualities that makes it an ideal place for
this study. To start, Jane Street developers use
a variety of testing tools, including PBT. This gives us a place to start
when asking questions, since participants will likely have seen PBT before,
and it means that will be score for exploring trade-offs between PBT and
other forms of testing.
Additionally, Jane Street developers famously build almost all of their
systems in OCaml, a mostly functional programming language with strong support
for static typing and modularity. This unified ecosystem
will allow
us to control for a number of potentially confounding factors: all of the
developers we talk to will have access to the same PBT tools and the same
libraries, language-level programming abstractions, house coding rules,
etc. (which might make testing easier or harder).

Naturally, carrying out a study at a single firm has potential drawbacks as
well. The most obvious is that our results may not generalize: We
cannot guarantee that our findings will apply outside of the OCaml ecosystem (and
other ecosystems like it). However, Jane Street is home to a diverse array of
software systems, including trading systems, quantitative
algorithms, networked systems, and hardware description code~\cite{signalsandthreads}.
We hope that the breadth of these programming tasks will mean that the software
developers that we talk to will come to the discussion with a wide variety of
experiences.

\textbf{Participants}.
Our initial discussions with Jane Street leadership made it clear that there are
two distinct populations at Jane Street that we can learn from. The group we had
initially planned to talk to was developers who have used PBT in
their work at the firm. These can tell us about how PBT helped them,
what challenges they faced, and what techniques they use instead of
PBT to check that their code is correct. For this group, we will interview 30 software developers employed by Jane Street across a variety of departments whom have had the chance to work with property-based testing tools.

We also intend to speak with builders and maintainers of PBT tools. These
tool-builders will help us reflect on the intended purposes of the tools,
features that were implemented but have not yet seen widespread use, and
practical considerations that might influence how future experimental features
would have to be designed and implemented to be incorporated into tools. Since talking with
stakeholders may also help us to refine our developer interview script, we will
interview them first.

\amh{[study design] I think we should consider also reaching out to software developers who are not at Jane Street, e.g., users of Hypothesis and QuickCheck who we could reach over public mailing lists, to try to reveal problems that might not come up at Jane Street due to difference in level of technical proficiency or different software development practices. Or, at least, we need to be ready to defend our choice of focusing exclusively on Jane Street when software development practices can vary greatly from firm to firm, from job to job. I think it is more problematic for a grant of this size (versus a single paper, say) to rely on a single company for its need-finding.}

\amh{[terminology] I think we should move away from describing the maintainers and tool-builders as stakeholders in the proposal and research reports, because technically the users of the tools are stakeholders as well. I think we should consider calling the groups ``tool users'' and ``tool builders'' or some other similar distinction.}

\textbf{Interview Plan}.
Each interview will be allotted a one hour slot, to account for a more detailed
interview script than the one in the preliminary study. As mentioned above, we
will start by interviewing stakeholders. Our prompts will primarily set the
stage for our developer interviews and establish background that will help us to
interpret our results, but stakeholders may also be able to help us answer {\bf
RQ4} (and to a lesser extent other research questions) directly. We will pick
the stakeholder's brains about opportunities to support users
of PBT, phrasing our prompts to encourage creative thinking.

After talking to stakeholders, we will begin the developer interviews. The
script for these interviews will depend on our conversations with stakeholders,
but at a high level we will aim to answer our research questions as directly as
possible. Much like the preliminary study, we will have our participants tell us about a
specific experience with PBT and ask them about the properties and generators
that they used (hopefully giving us insights about {\bf RQ1} and {\bf RQ2}).  We
will also ask about whether or not they are using PBT on their {\em current}
project (and if not, why not). Finally, we will ask questions addressing
{\bf RQ3} and {\bf RQ4} directly.

\textbf{Preliminary results}.
\todo{Shorten to about 1 page.}
We have conducted a preliminary interview study with 7 professional developers
who have experience using PBT tools.
What emerged were five categories of obstacles that developers encountered,
relating
to the design of properties, the definition of generators, learning PBT,
integrating PBT into team workflows, and achieving critical mass in the use of the tools.
In Section~\ref{sec:future}, we describe how these challenges
can help shape the research and design of usable PBT tools.
Below, we detail these challenges, referring to particular participants by
pseudonyms P1--7. Quotes from participants are lightly edited for clarity,
removing filler words and backtracking.
We note that, given the small scale of this preliminary study, some
of the obstacles are reflective of singular experiences, and the set of
obstacles may not be complete. This
highlights the need for expanded
studies of the sort we describe in Section~\ref{sec:full-scale} to confirm
and deepen our understanding of the usability of PBT tools.

\textit{Challenges Designing Properties}.
One common challenge for developers was to identify, design,
and articulate properties that would meaningfully test their code.

To begin with, developers seemed to have trouble identifying use-cases for PBT
that took advantage of the unique benefits of PBT over alternative approaches. While participants
did write properties, often times they either under-specified the
behavior of the system (for instance, simply testing that a program does not crash),
or over-specifying it (for instance, comparing to a behaviorally complete
{\em model} of the program under test, which might need to be separately
implemented) (P1, P3--5).
These participants were not testing properties as is conceptualized
in conventional PBT, which either undermined the power of their tests or
led to tests that could be brittle or time-consuming to implement.

In other cases, developer simply did not know how to express the notion of
correctness of their program as a property, which we call a failure
to ``imagine'' a property.
P1 described this as the problem of ``formulating the right property in the first place,''
a difficulty they had experienced despite prior successes using PBT according to
an over-specified model-based approach. P2 described circumstances in which this
challenge to imagine properties might arise: they were testing a complex numerical
computation involved in financial risk modeling. While they anticipated that
properties could help them test the validity of the computation better than their
existing suite of unit tests, they emphasized that determining such properties
was not at all straightforward.

Once a developer can imagine a property, the next challenge is to implement it.
Implementation challenges were of several sorts (P4--6). One
is common to software design generally---that module boundaries must be present
around the functionality to be tested. P6 described this as the challenge of
finding ``compose points where you can integrate [PBT] with the system.'' Refactoring
code to be testable can be tedious at best and prohibitively time-consuming at
worst. P6 reported that, for them, often the costs of restructuring code outstripped the benefits,
leading them not to use PBT where it might otherwise have been useful.

\textit{Challenges Writing Random Data Generators}.
Developers also faced obstacles writing data generators for their property-based
tests.
Some developers reported that they lacked support for generating the kinds of
distributions of input data that they felt were necessary for their tests.

P7 recounted testing an application where the inputs were network access control lists (ACLs)
with many different validity conditions, each given by
a different hardware vendor.
In this situation, P7 found that the {\em rejection sampling} approach to generation---generating
arbitrary ACLs and throwing out invalid ones---was too slow to be useful.
The standard solution would be to write a generator that enforces preconditions
by construction. Indeed, the participant did note that ``it might be possible to
make the generator smarter.'' However, they continued that it ``may or may not be worth it,'' due to
the complexity of generating access control lists that are valid for \emph{all}
of the vendors.

In another expected finding, some participants described difficulties with
controlling the distribution over test cases that their generators produce.
As P6 recounted, poor test-case distributions can lead to long testing times and missed bugs
as the generator repeatedly tries similar inputs and misses importantly different ones.
\begin{quote}
  I just relied on the built in [generators]. But\dots [there were] some tests
  that were running for quite a long time. Sometimes they were missing some
  useful use cases, just because the data distribution targeted use cases were
  missed by the default generators.
\end{quote}

Besides these technical issues,
participants encountered usability problems working with generator tools. P3 struggled to
write a generator in Hypothesis' generator DSL. They
explained that the (purely-functional style) abstraction did not match their expectations, given that Python is an imperative language, and they could
not ``hold it in [their] head very easily.'' This highlights the importance of
{\em idiomatic} generator abstractions.

\textit{Challenges Integrating PBT into Programmer Workflows}.
One unanticipated finding was that some participants struggled to incorporate
PBT into their team's development process. One issue
that came up was exactly where properties should be checked in the development pipeline.
P4 explained that they generally only check their properties in their
continuous integration (CI) system, because they are too slow to run locally.
However, they also pointed out that, because property-based testing finds
bugs at random, running PBT in CI is ``a bit like
Russian roulette, because sometimes the code breaks while you're working on
something totally unrelated.'' Indeed, P1 agreed that they preferred
to not have properties in CI for that reason.
% The tension created by PBT being
% both long-running and nondeterministic suggests a number of
% opportunities for research into improved PBT tooling and workflows \amh{[small fix] clearly spell out those opportunities here, or remove this.}.

\textit{Challenges Learning PBT}.
For some developers, the process of learning PBT proved a challenge in and of
itself.  While developers learned about PBT concepts from presentation
materials, library documentation, and blog posts, they sometimes found these
sources inaccessible or otherwise insufficient for learning how to apply PBT in practice.
For example, P4 described finding it challenging to understand the circumstances
in which to use PBT after having watched a presentation about it, and P1
expressed a desire for the library documentation to
include a comprehensive corpus of examples to use as starting points for their own tests:
\begin{quote}
  The hard part is knowing when you
  have a property that you can test and how to write that test. What
  would make it easier? I almost feel like more examples, you know,
  like\ldots{} just examples upon examples upon examples, so that you can just
  read through them and eventually hit one that, you know, hit a
  couple that click, and then those are clicked in your mind. And if you see
  that again, you can apply [them]?
\end{quote}

Developers also recounted trepidation at the idea of explaining PBT to
their organization's newcomers, fearing that it represented yet another unfamiliar
tool to learn in their already complex stack.
\begin{quote}
It's a bit scary, because every time I have to show the code base to a newcomer,
there is plenty of complicated things in the code base\ldots{} and when you
talk about all those things, which are complicated or interconnected, you
then go on, `By the way, there is this Hypothesis thing, which is really
a bit more complicated'\ldots{} so, *\emph{laughs}*\ldots{} I don't know if
when I talk about that people are too lost.
\end{quote}

\textit{The Critical Mass Problem}.
Finally, some of our participants' responses underlined a far more basic and
somewhat circular impediment to PBT adoption: for PBT to become widely adopted, it
must first become popular. This was best illustrated by P5,
when asked if they thought that PBT was missing any features that could help
drive adoption.
\begin{quote}
  Well, I think the problem is really more one of popularity, more than a
  technical problem. If lots of people use property based testing, then more
  people will be adept at using it.  And people will be more willing to write
  code that might support such a methodology of testing.
\end{quote}

P6 also implied a very similar problem when describing
how their managers reacted to a property-based test that found a potentially
severe bug. Despite their excitement around the success story, P6's
managers were unwilling to further invest in PBT due to its relative
unpopularity.
\begin{quote}
  They realize that [PBT is] very important and very useful, but can they find
  somebody to write those tests and maintain those tests? That's another
  question.
\end{quote}

This bootstrapping problem is not specific to PBT, but this is a helpful
reminder that solving both the
technical problems above and the as-of-yet hidden ones is necessary, but
likely not sufficient, to ensure broad adoption of PBT. To truly see PBT used across the software
industry, researchers need to convince developers, managers, and community
leaders, to invest in PBT without guarantees that it will take off.

We expect to learn more about these challenges, as well as about other challenges,
in depth during our interview study with Jane Street, to further refine our
understanding of the nature and impact of these challenges in the studies
described in subsequent sections, and to develop tooling to address
those challenges with the research described in Section~\ref{sec:tools}.

\subsubsection{Ongoing Work: Formative Study with Jane Street}

\subsubsection{Proposed Work: Validating Formative Results with a Survey}

\subsubsection{Proposed Work: Characterizing the Potential for Impact in Improved PBT Tools}

We will conduct a survey with the purpose of understanding the impact that
improved PBT tools could have in industry, if major usability issues were
addressed. We see this survey as crucial in understanding the amount of
resources that should be devoted to PBT research. Furthermore, this
questionnaire will help shed light into which of the usability challenges from
the interview study, if addressed, are most likely to impact a broad set of
current and prospective users of PBT tools.

\subsubsection{Proposed Work: Understanding the Structure of PBT Tasks in Detail}

The next step is to more deeply characterize the obstacles faced with specific
tools and tasks through close observation. We anticipate conducting observations
of participants formulating properties and creating generators, as we expect
that close observation of developers performing these tasks will yield yet
additional detail about ways that developers are supported and not supported by
the tools they use today to a level of depth we will not achieve with the
interviews.

\subsection{Specification: Step 1, Widening the On-Ramp to Properties \pagebudget{2.5}}
\subsubsection{Proposed Work: When to Specify It!}
\subsubsection{Proposed Work: Properties Over Printed Output}
\subsubsection{Proposed Work: Making Model-Based PBT First-Class}

\hg{Andrew wrote this for a slightly different thing}
Motivation: How do you design a generator DSL in an imperative language? A
generator uses higher-level functions in a way that might be confusing to people
who used Python.  (e.g., passing a generator of numbers to a generator of lists
to get randomized lists of numbers). Is there a way of designing APIs for
generators that can make the composition of these types of generators easier to
reason about and express for some programmers?

(Joe says the DSLs are well-designed, but the code is hard to debug. How do you
write a generator that works really well, that has a good data distribution and
finds bugs? See below.)

Plan of work. Not sure. This might require some discussions with more uses of
Hypothesis-like libraries.

Next steps—get examples of sloppily-expressed PBtests in Python and then think
through how they would be written more clearly.

\subsubsection{Proposed Work: Interactive Property Specification}

\bcp{General comment for this section: It all seems good, but it is a bit vague
and high level---I feel like technical readers will want a bit more meat.  Could
we spice it up with a concrete example?  (Indeed, should we be thinking about a
running example for the whole proposal?)} \amh{Agreed, I think a concrete
example would be \emph{great} here. Maybe there is an example we can bring in
from the QuickSpec paper~\cite{claessen2010quickspec}}

As our preliminary interview study has suggested, developers sometimes have
difficulty imagining which properties to test, even when they know that their
software would benefit from property-based testing. One area we are interested
in exploring is how programmers can work with their PBT tools to decide on a set
of significant properties to test.  Prior research demonstrates that automated
tools can extract specifications of a program's
behavior\cite{ammons2002mining,le2018deep,claessen2010quickspec}. We are
interested in the non-trivial research problem of integrating such techniques
into usable developer tools. We see the research as addressing several
challenges:

\textit{Generated properties should be \emph{important}}. Any non-trivial
program can be characterized by an overwhelmingly large number of properties,
many of which describe only incidental aspects of the program's behavior that do
not need to be tested. How can tools produce those properties that developers
would want to have tested? We believe that this is a problem that can be best
solved with a mixed-initiative approach~\cite{allen1999mixed}, where properties
are determined by judiciously incorporating both developer input and automated
techniques.

Developer could guide a specification mining tool to extracting relevant
properties through input mechanisms such as (1) identifying regions of code that
are likely to lead to an adverse behavior such as an exception or a logical
error; (2) providing unit test cases that test a special case of a generalized
property; and (3) indicating aspects of interest on input and output data during
exploration in a debugging REPL.

\textit{Generated properties should be \emph{readable}}. While prior research
has shown promise for automatically generating specifications of program
behavior, we expect that users of PBT systems would benefit from having
properties generated in the language of their property-based testing tools.
Furthermore, there are some variants about systems that may be so complex that
they require significant comprehension time for users (i.e., those involving a
large number of clauses). In such cases, a tool may way to generate simpler
variants of properties first, and allow developers to refine them on their own.

\textit{Tools should help developers \emph{revise} properties}. If a generated
property is too relaxed, the tool should request that developer provides a
counterexample that should trigger a failure, and then regenerate the property.
If a generated property is too strict, a tool should allow a programmer to mark
a counterexample that was generated by the PBT tool as spurious, i.e., not
indicating an actual failure of the program. In each of these cases, the
property generator may have generate multiple properties for a developer to
review, each of which may satisfy the refinements that a developer has provided.

\textit{Plan of work}: We will iteratively design and develop developer tools as
an extension to the VSCode editor, a popular development environment for
Haskell. In our first iterations, candidate properties will be generated using
QuickSpec~\cite{claessen2010quickspec}. The interactions described above will be
designed and tested first for simple programs, and then on successively more
complex programs from our benchmark set. PI Head has extensive experience
designing and developing developer tools involving program
analysis~\cite{head2018interactive,head2019managing} and program
synthesis~\cite{head2017writing} components, and extending the VSCode
environment~\cite{head2020composing}.  \bcp{Maybe consider focusing on OCaml
tools, rather than Haskell, since this is where there might be synergy with Jane
Street?  Or do both?} \amh{This is a great idea. Does anyone know of any
specification generators for OCaml?}

\subsection{Generation: Step 2, Better Tools for Random Inputs \pagebudget{3}}
\subsubsectionstar{Context: The Valid Generation Problem}%
%
Note that the property above has a {\em precondition} (which I also refer to
equivalently as a {\em validity condition} or {\em input constraint}): the
property is vacuous if the input tree is not a valid BST. This can be problematic,
because many preconditions are difficult to satisfy randomly; in the case above
we would need to randomly stumble on valid BSTs, which is very unlikely for
trees that are more than a few nodes deep. I call this the {\em valid generation
problem}. In the next section I will discuss the standard solution to this
problem in PBT---hand-written {\em monadic generators}---but first here is a
short overview of other options.

The solutions to the valid generation problem fall on a spectrum from fully
automatic to fully manual. The most automatic possible approach is to simply
generate inputs as normal, ignoring preconditions entirely, and throw away any
that do not satisfy the precondition. As I mentioned above, this is extremely
inefficient when the precondition is {\em sparse}, or unlikely to be satisfied
randomly.

Equally automatic, but often more effective, are coverage-guided approaches like
those used by {\em fuzzers}. Fuzzers like AFL~\cite{afl-readme} measure the code
coverage achieved by each input they try. If an input does not achieve coverage
of new program branches, it is discarded, but if the input is deemed
``interesting,'' then it may be mutated and tried again in an attempt to explore
even more new code paths. This process makes finding valid inputs more likely
because optimizing for code coverage encourages exploration of paths deeper in
the program (i.e., past the point where the precondition is checked).
Unfortunately, this only works so well, and again begins to fail with very
sparse preconditions.

A different approach that is {\em almost} entirely automatic is {\sc
Target}~\cite{loscher2017targetedpbt}; it uses search strategies like hill
climbing and simulated annealing to guide generation to more useful inputs.
\citeauthor{loscher2017targetedpbt}'s approach works well when the notion of
validity is in some way continuous (i.e., an input is not simply invalid, it is
$X\%$ valid), but this is often not the case.

Some approaches use machine learning to automatically generate valid inputs.
{\sc Learn\&Fuzz}~\cite{godefroid2017learn} generates valid data using a
recurrent neural network.  This solution seems to work best when a large corpus
of inputs is already available and the validity condition is more structural
than semantic. In the same vein, {\sc RLCheck}~\cite{DBLP:conf/icse/ReddyLPS20}
uses reinforcement learning to guide a generator to valid inputs.

For preconditions that are primarily structural, {\em grammar-based fuzzing}
provides a compelling (if slightly more manual) solution. In {\em
Grammar-based whitebox fuzzing}~\cite{godefroid2008grammar} a context-free
grammar (CFG) is used to constrain the fuzzer's output. Over the years, many
versions of this paradigm have been developed, including ones that use
pre-written fragments of the input language to give the mutator interesting
things to work with~\cite{holler2012fuzzing} and ones that use genetic
programming to find more interesting inputs~\cite{veggalam2016ifuzzer}. The
newest grammar-based fuzzing approaches use the grammar to do more structured
mutation of values~\cite{wang2019superion,srivastava2021gramatron}. These ideas have also been integrated
into PBT in the FuzzChick library~\cite{DBLP:journals/pacmpl/Lampropoulos0P19}.

Moving into the range of ``mostly manual'' solutions, there are a variety of
solver-aided languages for expressing generators for data with preconditions.
\citeauthor{dewey2017automated} proposed using constraint logic programming
(CLP) to define generators for interesting structures like Rust
programs~\cite{dewey2017automated}.  The {\sc Luck} language~\cite{LuckPOPL}
also uses a solver, but a bespoke one, to define generators and validity
predicates at the same time. \citet{steinhofel2022input} use a
grammar and SMT-expressible constraints on a structure to generate
precondition-satisfying values.

Finally, {\em Generating Good Generators}~\cite{lampropoulos2017generating} an
outlier on the spectrum: technically it is a manual approach since it requires
users to first express their validity predicates as inductive relations in Coq,
but in Coq it is likely that the user already has an inductive relation
available! {\em Generating Good Generators} is a great approach in the
situations where it applies.

\subsubsectionstar{Context: Monadic Generators}%
%
The most manual, but arguably the most flexible, solution to the valid
generation problem is write {\em monadic} generators.

We represent generators using {\em monads\/}~\cite{moggi1991notions}. A monad is
a type constructor (e.g., \lstinline{List}, \lstinline{Maybe}, etc.)
\lstinline{M} equipped with two operations,
\begin{lstlisting}
  return :: a -> M a
\end{lstlisting}
\noindent and
\begin{lstlisting}
  (>>=) :: M a -> (a -> M b) -> M b
\end{lstlisting}
\noindent (pronounced ``bind''). Conceptually, \lstinline{return} is the
simplest way to put some value into the monad, while bind gives a way to
sequence operations that produce monadic values.

We can use these operations to define {\sf genTree} like we would in QuickCheck:
\begin{lstlisting}
  genTree :: Int -> Gen Tree
  genTree 0 = return Leaf
  genTree $h$ = do
    c <- frequency [(1,False), (3,True)]
    case c of
      False -> return Leaf
      True -> do
        x <- genInt
        l <- genTree ($h$ - 1)
        r <- genTree ($h$ - 1)
        return (Node l x r)
\end{lstlisting}
We use the monadic operations (along with \lstinline{frequency}) to generate a
random tree of integers. The expression \lstinline{return Leaf} is a degenerate
generator that always produces the value \lstinline{Leaf}---this is what we mean
by the ``simplest way to put a value into the \lstinline{Gen} monad.''

Rather than use \lstinline{(>>=)} explicitly, we use \lstinline{do}-notation,
where
\begin{lstlisting}
  do
    a <- x
    f a
\end{lstlisting}
\noindent is syntactic sugar for \lstinline{x >>= f}. In the context of the
\lstinline{Gen} type, this operation samples from a generator \lstinline{x} to
get a value \lstinline{a} and then passes it to \lstinline{f} for further
processing---this is what we mean by ``sequencing operations.''

\smallskip

Monadic parsers are maximally expressive.  They can generate values satisfying
arbitrary computable constraints (e.g., it is possible to write a monadic
generator for well-typed System F terms), subsuming less powerful
representations like probabilistic context-free grammars.

For example, the following monadic generator generates (only) valid binary
search trees:
\begin{lstlisting}
  genBST :: (Int, Int) -> Gen Tree
  genBST (lo, hi) | lo > hi = return Leaf
  genBST (lo, hi) = do
    c <- frequency [(1,False), (3,True)]
    case c of
      False -> return Leaf
      True -> do
        x <- genRange (lo, hi)
        l <- genBST (lo, x - 1)
        r <- genBST (x + 1, hi)
        return (Node l x r)
\end{lstlisting}
\noindent The generator maintains the BST invariant by keeping track of the
minimum and maximum values available for a given sub-tree and ensuring that all
values to the left of a value are less and that all values to the right of a
value are greater.  This kind of generator is impossible to express as a
stochastic CFG, since there is dependence between the choice of value
\lstinline{x} and the choices of sub-trees. Our examples are mostly focused on
simple (non-dependent) generators to streamline the exposition, but our theory
applies to the full class of monadic generators with finitely supported
distributions.

\subsubsection{Prior Work: Free Generators}
\subsubsection{Ongoing Work: Reflective Generators}
\subsubsection{Proposed Work: Bringing Fuzzing into Focus}
\subsubsection{Proposed Work: Reflective Shrinking}

\subsection{Validation: Step 3, Understanding Testing Effectiveness \pagebudget{2.5}}
\subsubsection{Ongoing Work: Empirically Evaluating PBT Tools}

\subsubsection{Proposed Work: Visualizing and Tuning Data Distributions}

Plan of work: easily computable summary statistics; as well as user-defined
metrics for understanding what you care the most about from the distribution.
Seeing what the “average” data structure is that is getting generated. For
multimodal data, what are the different modes of data. The set of data types to
be handled in PBT are: algebraic data types, lists, trees (this would also cover
programs). Joe thinks we already have good visualizations for numbers, booleans,
and strings; it is compositional data types that we lack good visualizations
for. People need to (1) see representative examples (2) understand spread (3)
indicate areas of the space that should not be explored.  \bcp{I love this
thread---understanding the distribution that you're getting from a random
generator is one of the most challenging aspects of PBT---the thing that makes
it an art rather than a pushbutton or even fully automatable activity.  (We
should acknowledge this challenge even more clearly and prominently, at the very
top.)  Jessica and I have been struggling just this week to figure out what to
measure to get a better understanding of some specific distributions!  I feel
like there must be a ton or two of work on this, in adjacent or distant
communities.  I wonder how we'd find it...} \amh{Currently the project ideas are
arranged chronologically according to when programmers would use them (i.e.,
first they would write properties, then generators, then understand their
solutions, then integrate the tests into continuous integration, etc.). I could
see also ordering by our level of enthusiasm / likelihood to work on it, which,
as I understand, would put this section at the top.}

Plan of work: indicating areas of the distribution that should not be generated.

Example: writing a generator of programs (for instance, to test out a compiler).
You want lots of different programs that make sense in different ways. You want
large ones, small ones, ones that use variables in coherent ways, ones that
don’t overuse certain constructs, ones that use a variety of different language
features. You want the generated programs to be representative of those that
people might write. You also want some weird programs to catch the edge cases,
but you don’t want all weird programs. (How big, how deep, how wide of
programs?). Also, for trees, one might want to specify heights and breadths of
the tree.


\subsubsection{Proposed Work: Debugging Support for Understanding Counterexamples}

Once a PBT tool generates a counterexample of where a property fails, a
programmer will need to understand what in an input caused the program to fail.
This task can be rather challenging because generated inputs can be complex,
deep data structures \todo{Do we have a reference that implies the complexity of
generated counterexamples?}. Methods for making it clearer why a counterexample
fails could be to generate additional inputs that are very close to the
counterexample that are actually correct, to run the program up to the point
where the traces of the programs begin to diverge, and then to drop a programmer
into a debugging environment where they can query the state of the program and
step through the remainder of the execution. PI Head has prior work designing
debugging tools that help programmers understand trace divergences in an
educational setting~\cite{suzuki2017tracediff}.  \bcp{This sounds very cool!  We
should acknowledge all the work that's been done on shrinking in the PBT
community.} \amh{Good thinking!}
\hg{Hila had a similar idea that she wanted one of her undergrads to work on, we
should make sure we don't step on toes}

\subsubsection{Proposed Work: Integration with Continuous Integration Workflows}

The preliminary study suggests that one area that new developer tooling may be
needed is in managing the interplay between PBT and continuous integration (CI)
systems. Recall that developers we spoke with pointed out frustration with the
fact that PBT is both nondeterministic and long-running. This combination left
them unsure of exactly where and when to test their properties: testing
properties locally slowed down their workflow, but testing them in CI
occasionally led them to find bugs at inconvenient times.

It is likely that PBT tools could play a role in improving this state of
affairs. For example, one could take inspiration from some theorem
provers~\cite{berghofer2004random} and create a system in which properties are
checked locally but in the background, as the programmer works on other things.
This avoids waiting time while potentially being less frustrating than running
in CI, since bugs would likely be found while the programmer still had the code
``paged in.'' Alternatively, one might design a PBT system with CI in mind,
providing automated features for deferring property failure notifications until
a specified time or turning failing properties into unit tests that can be saved
for future testing.

If the full-scale study indicates that this would be a useful line of work, we
will refine these ideas via user-centered design. Rather than build a system and
hope users like it, we will build minimal prototypes and iterate on the design
by observing testers using it. Ultimately we hope this will guide us to a tool
that will meaningfully improve the experience of PBT.

\subsection{Education: Advancing Testing in the Broader Culture \pagebudget{1}}

The preliminary study also reminded us that PBT builds on concepts that are not
always comfortable for developers, and we expect that we will learn more about
the specifics of that discomfort in the large-scale study.  Prior work has
explored ways to close this knowledge
gap~\cite{wrenn2021using,nelson2021automated}, but we expect there are further
education challenges that are worth exploring.

I hope to work with the course staff of CIS 1210 to incorporate PBT into the
curriculum. The ideal scenario would be to add a PBT thread throughout the
course, giving students the tools to specify and test their code as they go.  I
plan to follow the lead of others who have done similar things before (e.g., the
PL folks at Brown University) to give students the best chance at incorporating
PBT into their tool-set.

There are a few important challenges that need to be considered in order for
this to work out.  The curriculum is already quite full, so adding PBT likely
means removing something else. I will need to work with the professors currently
teaching the course to find room, but I expect that this process will be fairly
difficult. It is also possible that adding PBT will actually make parts of the
course {\em easier}, especially for students with some knowledge of logic and/or
less well-developed unit testing instincts. Honestly I think this is a good
thing, as it gives students more ways to succeed and it may re-enforce the value
of PBT, but some may find this problematic.

\subsection{Plan of Work \pagebudget{.5}}

\todo{(with a pretty pert chart or suchlike...)}

\subsection{Broader Impacts \pagebudget{.5}}
The Project Description must contain, as a separate section within the narrative, a section labeled ``Broader
Impacts of the Proposed Work". This section should provide a discussion of the broader impacts of the proposed
activities. Broader impacts may be accomplished through the research itself, through the activities that are
directly related to specific research projects, or through activities that are supported by, but are complementary to
the project. NSF values the advancement of scientific knowledge and activities that contribute to the
achievement of societally relevant outcomes. Such outcomes include, but are not limited to: full
participation of women, persons with disabilities, and underrepresented minorities in science, technology, engineering, and
mathematics (STEM); improved STEM education and educator development at any level; increased public
scientific literacy and public engagement with science and technology; improved well-being of individuals in
society; development of a diverse,globally competitive STEM workforce; increased partnerships between
academia, industry, and others; improved national security; increased economic competitiveness of the United
States; and enhanced infrastructure for research and education.

\subsection{Results from Prior NSF Support \pagebudget{.5}}
If any PI or co-PI identified on the project has received NSF funding (including any current
funding) in the past five years, in formation on the award(s) is required,
irrespective of whether the support was directly related to the proposal or not.
In cases where the PI or co-PI has received more than one award (excluding amendments),
they need only report on the one award most closely related to the proposal. Funding includes not just salary
support, but any funding awarded by NSF. The following information must be provided:\\

\noindent
\emph{\underline{Name of PI}}: NSF-Program (Award Number) ``Title of the Project'' (\$AMOUNT, PERIOD OF SUPPORT).
{\bf Publications:} List of publications resulting from the NSF award. A complete bibliographic citation for each
publication must be provided either in this section or in the References Cited section of the proposal); if
none, state: ``No publications were produced under this award.'' {\bf Research Products:} evidence of research products
and their availability, including, but not limited to: data, publications, samples, physical collections, software,
and models, as described in any Data Management Plan.

% \subsubsection{Proposed Study}
% The Project Description should provide a clear statement of the work to be undertaken and must include:
% objectives for the period of the proposed work and expected significance; relation to longer-term goals of the PI's
% project; and relation to the present state of knowledge in the field, to work in progress by the PI under other
% support and to work in progress elsewhere.
%
% The Project Description should outline the general plan of work, including the broad design of activities to be
% undertaken, and, where appropriate, provide a clear description of experimental methods and procedures.
% Proposers should address what they want to do, why they want to do it, how they plan to do it, how they will
% know if they succeed, and what benefits could accrue if the project is successful. The project activities may be
% based on previously established and/or innovative methods and approaches, but in either case must be well
% justified. These issues apply to both the technical aspects of the proposal and the way in which the project may
% make broader contributions.

\subsectionstar{More stuff to not forget :-)}

Unfunded collaborations: Any substantial collaboration with individuals not included in the budget should be described in the Facilities, Equipment and Other Resources section of the proposal (see Chapter II.C.2.i) and documented in a letter of collaboration from each collaborator. Such letters should be provided in the supplementary documentation section of FastLane or Research.gov and follow the format instructions specified in Chapter II.C.2.j. Collaborative activities that are identified in the budget should follow the instructions in Chapter II.D.3.

Remember to not use any URLs in the project description!  (They are
encouraged in the references.)
